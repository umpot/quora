1)rare words
2)upper words
3)entities
4)stop words
5)remove PRON, PREP etc
6)how\what\why features
7)frequent words for questions 'difference', 'best way', 'how much', 'better' etc
8)clusters for 'question type' ?
9)Punctuations .,!
10)Special things [math], http:// facebook youtube etc
11)word_match_share/stem share/lemma share
12)Pronoun feature (I you he she mine etc)
13)Prep feature (of in )
14)Conditional feature (if ) ????
15)time related features nums 1900-2100, words like 'while', 'during', words like year, decade, century
16)tfidf_word_match_share
17)can have if could - features for this stopwords?!!!!
18)word_share nouns\nouns not top\PN-s !!!! verbs\adj\adv

19)tfidf features on Upper Tokens\Ner\Nouns-Adj-Verbs etc
20)unique NER or Upper

21)Fetaures like 'Quantity' '20mg three times' in question1 but not in q2, or similarity small, or there is no similar substring
22)year in question 1999 or None

23)most frequent start word n-grams 'what is' 'how somebody could' etc
    ++++ bayesian encoding on this categorical features
    ++++ special features for the most frequent prefixes
    ++++ prefix frequency


24)length of longest common prefix word\char

25)CV - split in the same proportion as train\test

26)Tf but different idf(1/log^2, 1/sqrt etc)

27)keyword extraction (simple for (example: top3 word by tfidf)), papers or frameworks
28)Many custom 'similarity'-metrics.
Ner-intersections(jacard, first, idf),
topN idf - share-idf-df, jacard, etc
topN idf form NOUNS(postag)
NNP	Proper noun
different keyword extraction algorithms
Upper -words shares, jacard
prefixes-similarity
nouns-verbs-adj
word2vec distances on keywords
pair distances between representation words

Problems:fancy words(adjectives??)
Problems:India, Pakistan, iphone

29)Cumulative list of key-words, Ner+topN by idf + ProperNouns
some 'mixed' sets key-words + one verb(largest idf)

30)Topic detection, scores for quora topics
a)clustering + word2vec, bag-of-words, etc

31)measure how 'common' is a question, tfidf?
        freq of words from 'l'-percintile by frequency

32)by-ner-features is_there_country, is_there_name, is_there_year etc, [(u'EVENT', 'World War 1')]


33)dissimilarity metrics!!!

34)weighted tfidf-share, wmd

35)Conversations:,  ('Surveillance:', 5) etc

36)words_hamming NO
37)FIX TFIDF SHARE 0 ===> NONE

38)hash   !!!!!!!!!!!!!!!!!!!!!!

39)VERBS!!!!!!!!!!
40)
contains URL!!!!! {'neg': 0.924625468164794, 'pos': 0.075374531835206} + '.' + numbers
strange {'neg': 0.7379757847319875, 'pos': 0.2620242152680125}
has_number Out[15]: {'neg': 0.6968679045752854, 'pos': 0.30313209542471464}
2016 in    {'neg': 0.5139010316488897, 'pos': 0.4860989683511103}!!!!!
both contains 2016 {'neg': 0.3574488338886245, 'pos': 0.6425511661113755}   !!!!!!!!!!!!!!!!!!!
Frequent not word tokens ????
less_frequent_non_words {'neg': 0.7833446174678402, 'pos': 0.2166553825321598}
frequent upper {'neg': 0.5589146654707058, 'pos': 0.44108533452929427}
Android {'neg': 0.7879633320047827, 'pos': 0.21203666799521723}
Trump {'neg': 0.36682682264466265, 'pos': 0.6331731773553374}



avg freq? min freq ?

41)One Upper-word diff
frequencies(avg) of diff-tokens, is diff token stop, auxial

42)magic combinations q1_freq\q2_freq etc
43)hand-tuning most frequent

44)Frequency of target when some combo of words present in q1(q1 and q2)!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

45)india!!!!!
india=set(['demonetization', 'india', 'rs', 'rs,', '500', '1000', 'rupee', 'ban'])
trump=set(['trump', 'donald', 'clinton', 'hillary','presidential'])
x=df[df[in_q1]>1]
{'neg': 0.038034331874789634, 'pos': 0.9619656681252103}
z=df[(df[in_q1]>1)&(df[in_q2]>1)]

46)one keyword inn!
x=df[df[inn]==-1]
explore_target_ratio(x)
Out[10]: {'neg': 0.9753694581280788, 'pos': 0.024630541871921183}

x=df[df[inn]==1]
explore_target_ratio(x)
Out[12]: {'neg': 0.8087954110898662, 'pos': 0.19120458891013384}



47)non-askii  {'neg': 0.7278844250940035, 'pos': 0.2721155749059964}

48)separete features for each stop-word:
you
1: len=24603, {'neg': 0.4636832906556111, 'pos': 0.5363167093443889}
-1: len=51523, {'neg': 0.6922151272247345, 'pos': 0.3077848727752654}

49)For most 'separating' tokens????

50)Some AVG on this separating-frequencies ?????
For same tokens, for different tokens, weighted, max, min etc

51)features for hot topics!!!!!!!!!!!!!!!!!!!!!
features for the most freq similar questions (Ra 500-1000, loose weight, Learn English)
detectors, mini classifiers? 500 Rupee detector, lose-weight-detector

df = train_df[train_df[question1].apply(lambda s: '1000' in s)]
{'neg': 0.10990502035278155, 'pos': 0.8900949796472184}/{'neg': 0.12927551844869378, 'pos': 0.8707244815513062} q2


52)What universities does Newfield Exploration recruit new grads from? What majors are they looking
 What universities does Icon Exploration recruit new grads from? What majors are they looking for?
 difference only in upper
 def diff_only_upper(a,b):
     x = set(a.split()).intersection(set(b.split()))
     if len(x) == 0:
         return False
     for y in x:
         if not y.isupper():
             return False
     return True

  {'neg': 0.9302678120262758, 'pos': 0.0697321879737241}


53)Strange Only-Locadion-Difff:
'What are the safety precautions on handling shotguns proposed' in s
{'neg': 0.023622047244094488, 'pos': 0.9763779527559056}



54)Bayesian frequencies on pairs of prefixes, question-types

55)Mix of type-of-question distances/bayesian freq with Nouns/Uppers/keywords/big tfidf  distances/bayesian

56)person feature has\have\I\you\me\they etc

57)bl = df[df[question1].apply(lambda s: 'math]' in s)]  700-instances
{'neg': 0.9369565217391305, 'pos': 0.06304347826086956}

58)textacy topic-modeling
59)subject-verb-object triples !!!!!!!!! textacy, spacy, noun_chunks
60)textacy textrank keywords!!!! get_information_content
61)textacy Fleschâ€“Kincaid readability tests

62)adjectives (superlative, comparative), adverbs, pronouns(possesive pronouns)
determiners (all/some/any),
MD(modals!! can, will, should)
RP(out, up),
CC(and, but, or)
CD(1990, one, million)


63)wmd, norm-wmd, tfidf-shares on diffrent subsets, POS, top-idf, Nouns, adjectives
without stops, without nouns, without verbs etc


64)maybe modals, wh - features ?????

xx)stop_words_ratio_q1-stop_words_ratio_q2, stop_words_ratio_q1/stop_words_ratio_q2 etc

xx)Jackard\Dice\etc on ngrams
